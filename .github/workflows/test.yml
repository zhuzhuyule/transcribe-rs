name: Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  CARGO_TERM_COLOR: always

jobs:
  test:
    name: Test on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]

    steps:
      - uses: actions/checkout@v6

      - name: Set up Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Rust Cache
        uses: Swatinem/rust-cache@v2

      - name: Setup Vulkan (Linux)
        if: runner.os == 'Linux'
        run: |
          wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo tee /etc/apt/trusted.gpg.d/lunarg.asc
          sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list https://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list
          sudo apt-get update
          sudo apt-get install -y vulkan-sdk
          echo "VULKAN_SDK=/usr" >> $GITHUB_ENV

      - name: Setup Vulkan (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          Invoke-WebRequest -Uri "https://sdk.lunarg.com/sdk/download/latest/windows/vulkan-sdk.exe" -OutFile "vulkan-sdk.exe"
          Start-Process -FilePath "vulkan-sdk.exe" -ArgumentList "--root C:\VulkanSDK --accept-licenses --default-answer --confirm-command install" -Wait -NoNewWindow
          echo "VULKAN_SDK=C:\VulkanSDK" | Out-File -FilePath $env:GITHUB_ENV -Append

      - name: Install dependencies (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get install -y libasound2-dev pkg-config cmake

      - name: Run Tests (Default Features)
        run: cargo test

      - name: Cache Moonshine Model
        id: cache-moonshine
        uses: actions/cache@v5
        with:
          path: models/moonshine-base/
          key: ${{ runner.os }}-moonshine-base-v1

      - name: Download Moonshine
        if: steps.cache-moonshine.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p models/moonshine-base
          cd models/moonshine-base
          curl -sLO https://huggingface.co/onnx-community/moonshine-base-ONNX/resolve/main/onnx/encoder_model.onnx
          curl -sLO https://huggingface.co/onnx-community/moonshine-base-ONNX/resolve/main/onnx/decoder_model_merged.onnx
          curl -sLO https://huggingface.co/onnx-community/moonshine-base-ONNX/resolve/main/tokenizer.json

      - name: Run Tests (Moonshine)
        run: cargo test --features moonshine

      - name: Cache Parakeet Model
        id: cache-parakeet
        uses: actions/cache@v5
        with:
          path: models/parakeet-tdt-0.6b-v3-int8/
          key: ${{ runner.os }}-parakeet-v1

      - name: Download Parakeet
        if: steps.cache-parakeet.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p models
          curl -sL https://blob.handy.computer/parakeet-v3-int8.tar.gz | tar -xz -C models/

      - name: Run Tests (Parakeet)
        run: cargo test --features parakeet

      - name: Cache SenseVoice Model
        id: cache-sensevoice
        uses: actions/cache@v5
        with:
          path: models/sense-voice-int8/
          key: ${{ runner.os }}-sensevoice-v1

      - name: Download SenseVoice
        if: steps.cache-sensevoice.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p models
          curl -sL https://blob.handy.computer/sense-voice-int8.tar.gz | tar -xz -C models/

      - name: Run Tests (SenseVoice)
        run: cargo test --features sense_voice

      - name: Cache Whisper Model
        id: cache-whisper
        uses: actions/cache@v5
        with:
          path: models/whisper-medium-q4_1.bin
          key: ${{ runner.os }}-whisper-medium-v1

      - name: Download Whisper
        if: steps.cache-whisper.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p models
          curl -sLo models/whisper-medium-q4_1.bin https://blob.handy.computer/whisper-medium-q4_1.bin

      - name: Run Tests (Whisper)
        run: cargo test --features whisper

      - name: Cache Whisperfile Resources
        id: cache-whisperfile
        uses: actions/cache@v5
        with:
          path: |
            models/ggml-small.bin
            models/whisperfile-*
          key: ${{ runner.os }}-whisperfile-v1

      - name: Download Whisperfile
        if: steps.cache-whisperfile.outputs.cache-hit != 'true'
        shell: bash
        run: |
          mkdir -p models
          curl -sLo models/ggml-small.bin https://blob.handy.computer/ggml-small.bin

          if [ "$RUNNER_OS" == "Windows" ]; then
            curl -sLo models/whisperfile-0.9.3.exe https://github.com/mozilla-ai/llamafile/releases/download/0.9.3/whisperfile-0.9.3
          else
            curl -sLo models/whisperfile-0.9.3 https://github.com/mozilla-ai/llamafile/releases/download/0.9.3/whisperfile-0.9.3
          fi

      - name: Run Tests (Whisperfile)
        shell: bash
        run: |
          if [ "$RUNNER_OS" != "Windows" ]; then
            chmod +x models/whisperfile-0.9.3 || true
          fi

          if [ "$RUNNER_OS" == "Windows" ]; then
            export WHISPERFILE_BIN="models/whisperfile-0.9.3.exe"
          else
            export WHISPERFILE_BIN="models/whisperfile-0.9.3"
          fi
          export WHISPERFILE_MODEL="models/ggml-small.bin"

          if [ -f "$WHISPERFILE_BIN" ]; then
            cargo test --features whisperfile
          else
            echo "Skipping whisperfile tests due to missing binary at $WHISPERFILE_BIN"
          fi
